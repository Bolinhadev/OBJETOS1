<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detecção Otimizada de Objetos e Pose</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: #000;
            overflow: hidden;
            font-family: Arial, sans-serif;
        }
        #container {
            position: relative;
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        video, canvas {
            position: absolute;
            max-width: 100%;
            max-height: 100%;
            width: auto;
            height: auto;
        }
        #loading {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: rgba(0,0,0,0.8);
            color: white;
            padding: 20px;
            border-radius: 10px;
            z-index: 1000;
        }
    </style>
</head>
<body>
    <div id="container">
        <video id="video" autoplay muted playsinline></video>
        <canvas id="canvas"></canvas>
    </div>
    <div id="loading">Carregando modelos...</div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const loadingElement = document.getElementById('loading');

        let mobileNetModel, poseNetModel;
        const confidenceThreshold = 0.5;

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { width: 640, height: 480, facingMode: 'environment' } 
            });
            video.srcObject = stream;
            return new Promise(resolve => {
                video.onloadedmetadata = () => {
                    video.play();
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    resolve();
                };
            });
        }

        async function loadModels() {
            mobileNetModel = await mobilenet.load({ version: 2, alpha: 1.0 });
            poseNetModel = await posenet.load({
                architecture: 'MobileNetV1',
                outputStride: 16,
                inputResolution: { width: 640, height: 480 },
                multiplier: 0.75
            });
            loadingElement.style.display = 'none';
        }

        async function detectObjectsAndPose() {
            // Objeto detecção
            const predictions = await mobileNetModel.classify(video);
            
            // Pose detecção
            const pose = await poseNetModel.estimateSinglePose(video, {
                flipHorizontal: false
            });

            // Limpar canvas
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            // Desenhar detecções de objetos
            predictions.forEach((prediction, index) => {
                if (prediction.probability > confidenceThreshold) {
                    const y = 30 + index * 30;
                    ctx.fillStyle = 'rgba(0, 255, 0, 0.5)';
                    ctx.fillRect(10, y - 20, 300, 25);
                    ctx.fillStyle = 'white';
                    ctx.font = '16px Arial';
                    ctx.fillText(`${prediction.className} (${Math.round(prediction.probability * 100)}%)`, 15, y);
                }
            });

            // Desenhar pose
            drawKeypoints(pose.keypoints);
            drawSkeleton(pose.keypoints);

            requestAnimationFrame(detectObjectsAndPose);
        }

        function drawKeypoints(keypoints) {
            keypoints.forEach(keypoint => {
                if (keypoint.score > confidenceThreshold) {
                    const { y, x } = keypoint.position;
                    ctx.beginPath();
                    ctx.arc(x, y, 5, 0, 2 * Math.PI);
                    ctx.fillStyle = 'red';
                    ctx.fill();
                }
            });
        }

        function drawSkeleton(keypoints) {
            const skeleton = [
                ['nose', 'leftEye'], ['leftEye', 'leftEar'], ['nose', 'rightEye'], ['rightEye', 'rightEar'],
                ['leftShoulder', 'rightShoulder'], ['leftShoulder', 'leftElbow'],
                ['leftElbow', 'leftWrist'], ['rightShoulder', 'rightElbow'], ['rightElbow', 'rightWrist'],
                ['leftShoulder', 'leftHip'], ['rightShoulder', 'rightHip'], ['leftHip', 'rightHip'],
                ['leftHip', 'leftKnee'], ['leftKnee', 'leftAnkle'], ['rightHip', 'rightKnee'],
                ['rightKnee', 'rightAnkle']
            ];

            skeleton.forEach(([startPoint, endPoint]) => {
                const start = keypoints.find(kp => kp.part === startPoint);
                const end = keypoints.find(kp => kp.part === endPoint);

                if (start && end && start.score > confidenceThreshold && end.score > confidenceThreshold) {
                    ctx.beginPath();
                    ctx.moveTo(start.position.x, start.position.y);
                    ctx.lineTo(end.position.x, end.position.y);
                    ctx.strokeStyle = 'blue';
                    ctx.lineWidth = 2;
                    ctx.stroke();
                }
            });
        }

        async function start() {
            await setupCamera();
            await loadModels();
            detectObjectsAndPose();
        }

        start();
    </script>
</body>
</html>
