<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detecção Otimizada de Objetos e Mãos</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: #000;
            overflow: hidden;
        }
        #container {
            position: relative;
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        video, canvas {
            position: absolute;
            max-width: 100%;
            max-height: 100%;
            width: auto;
            height: auto;
        }
        #loading {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: rgba(0,0,0,0.8);
            color: white;
            padding: 20px;
            border-radius: 10px;
            z-index: 1000;
        }
    </style>
</head>
<body>
    <div id="container">
        <video id="video" autoplay muted></video>
        <canvas id="canvas"></canvas>
    </div>
    <div id="loading">Carregando modelos...</div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const loadingElement = document.getElementById('loading');

        let mobileNetModel;
        let handsModel;
        let camera;
        const confidenceThreshold = 0.3;

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { width: 640, height: 480, facingMode: 'environment' } 
            });
            video.srcObject = stream;
            return new Promise(resolve => {
                video.onloadedmetadata = () => {
                    video.play();
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    resolve();
                };
            });
        }

        async function loadModels() {
            mobileNetModel = await mobilenet.load({ version: 2, alpha: 1.0 });
            handsModel = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
            await handsModel.setOptions({
                maxNumHands: 2,
                modelComplexity: 0,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });
            handsModel.onResults(onHandResults);
            loadingElement.style.display = 'none';
        }

        async function detectObjects() {
            const predictions = await mobileNetModel.classify(video);
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            predictions.forEach((prediction, index) => {
                if (prediction.probability > confidenceThreshold) {
                    const y = 30 + index * 30;
                    ctx.fillStyle = 'rgba(0, 255, 0, 0.5)';
                    ctx.fillRect(10, y - 20, 300, 25);
                    ctx.fillStyle = 'white';
                    ctx.font = '16px Arial';
                    ctx.fillText(`${prediction.className} (${Math.round(prediction.probability * 100)}%)`, 15, y);
                }
            });

            requestAnimationFrame(detectObjects);
        }

        function onHandResults(results) {
            if (results.multiHandLandmarks) {
                for (const landmarks of results.multiHandLandmarks) {
                    drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {color: '#00FF00', lineWidth: 3});
                    drawLandmarks(ctx, landmarks, {color: '#FF0000', lineWidth: 1});
                }
            }
        }

        async function startCamera() {
            camera = new Camera(video, {
                onFrame: async () => {
                    await handsModel.send({image: video});
                },
                width: 640,
                height: 480
            });
            camera.start();
        }

        async function start() {
            await setupCamera();
            await loadModels();
            await startCamera();
            detectObjects();
        }

        start();
    </script>
</body>
</html>
