<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detecção Leve de Faces e Pontos-Chave</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: #000;
            overflow: hidden;
        }
        #container {
            position: relative;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        #loading {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: rgba(0,0,0,0.8);
            color: white;
            padding: 20px;
            border-radius: 10px;
            z-index: 1000;
        }
    </style>
</head>
<body>
    <div id="container">
        <video id="video" width="640" height="480" autoplay muted></video>
        <canvas id="canvas" width="640" height="480"></canvas>
    </div>
    <div id="loading">Carregando modelo... <span id="progress">0%</span></div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const loadingElement = document.getElementById('loading');
        const progressElement = document.getElementById('progress');

        let blazefaceModel;
        let isProcessing = false;

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });
            video.srcObject = stream;
            return new Promise(resolve => {
                video.onloadedmetadata = () => {
                    video.play();
                    resolve();
                };
            });
        }

        async function loadModel() {
            try {
                blazefaceModel = await blazeface.load();
                console.log('BlazeFace modelo carregado.');
                progressElement.textContent = '100%';
                loadingElement.style.display = 'none';
            } catch (error) {
                console.error('Erro ao carregar o modelo:', error);
            }
        }

        async function detectFaces() {
            if (isProcessing || !blazefaceModel) return;
            isProcessing = true;

            try {
                const predictions = await blazefaceModel.estimateFaces(video, false);
                
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                predictions.forEach(face => {
                    // Desenhar caixa do rosto
                    ctx.strokeStyle = 'green';
                    ctx.lineWidth = 2;
                    ctx.strokeRect(
                        face.topLeft[0], face.topLeft[1],
                        face.bottomRight[0] - face.topLeft[0],
                        face.bottomRight[1] - face.topLeft[1]
                    );

                    // Desenhar pontos-chave
                    ctx.fillStyle = 'red';
                    face.landmarks.forEach(landmark => {
                        ctx.beginPath();
                        ctx.arc(landmark[0], landmark[1], 3, 0, 2 * Math.PI);
                        ctx.fill();
                    });

                    // Adicionar texto com probabilidade
                    ctx.fillStyle = 'white';
                    ctx.font = '16px Arial';
                    ctx.fillText(
                        `Confiança: ${(face.probability[0] * 100).toFixed(2)}%`,
                        face.topLeft[0],
                        face.topLeft[1] - 5
                    );
                });

            } catch (error) {
                console.error('Erro na detecção:', error);
            }

            isProcessing = false;
        }

        function processFrame() {
            detectFaces();
            requestAnimationFrame(processFrame);
        }

        async function start() {
            await setupCamera();
            await loadModel();
            processFrame();
        }

        start();
    </script>
</body>
</html>
